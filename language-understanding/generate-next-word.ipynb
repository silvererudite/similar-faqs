{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-17T08:34:46.675785Z","iopub.execute_input":"2022-12-17T08:34:46.676408Z","iopub.status.idle":"2022-12-17T08:34:47.673011Z","shell.execute_reply.started":"2022-12-17T08:34:46.676330Z","shell.execute_reply":"2022-12-17T08:34:47.671821Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_df = pd.read_csv('/kaggle/input/slogan-dataset/sloganlist.csv')\ndata_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:47.674935Z","iopub.execute_input":"2022-12-17T08:34:47.675234Z","iopub.status.idle":"2022-12-17T08:34:47.710884Z","shell.execute_reply.started":"2022-12-17T08:34:47.675207Z","shell.execute_reply":"2022-12-17T08:34:47.709353Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"        Company                          Slogan\n0  Costa Coffee              For coffee lovers.\n1         Evian              Evian. Live young.\n2        Dasani  Designed to make a difference.\n3      Heineken        It's all about the beer.\n4      Gatorade           The Legend Continues.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Company</th>\n      <th>Slogan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Costa Coffee</td>\n      <td>For coffee lovers.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Evian</td>\n      <td>Evian. Live young.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dasani</td>\n      <td>Designed to make a difference.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Heineken</td>\n      <td>It's all about the beer.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gatorade</td>\n      <td>The Legend Continues.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_df['slogan_len'] = data_df['Slogan'].apply(lambda x: len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:47.712994Z","iopub.execute_input":"2022-12-17T08:34:47.713463Z","iopub.status.idle":"2022-12-17T08:34:47.721884Z","shell.execute_reply.started":"2022-12-17T08:34:47.713439Z","shell.execute_reply":"2022-12-17T08:34:47.721082Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data_df['slogan_len'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:47.724602Z","iopub.execute_input":"2022-12-17T08:34:47.725705Z","iopub.status.idle":"2022-12-17T08:34:47.741551Z","shell.execute_reply.started":"2022-12-17T08:34:47.725634Z","shell.execute_reply":"2022-12-17T08:34:47.740426Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"count    1162.000000\nmean        3.839071\nstd         1.280244\nmin         2.000000\n25%         3.000000\n50%         3.000000\n75%         5.000000\nmax        10.000000\nName: slogan_len, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"unique_words = set()\nfor i, row in data_df.iterrows():\n    for word in row['Slogan'].split():\n        unique_words.add(word.lower())\n        ","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:47.742977Z","iopub.execute_input":"2022-12-17T08:34:47.743215Z","iopub.status.idle":"2022-12-17T08:34:47.809390Z","shell.execute_reply.started":"2022-12-17T08:34:47.743191Z","shell.execute_reply":"2022-12-17T08:34:47.807794Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"words_sorted = sorted(unique_words)\nword2int = {word:i for i,word in enumerate(words_sorted)}\nword_array = np.array(words_sorted)\nwords_encoded = np.array([word2int[ch] for ch in unique_words],dtype=np.int32)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:47.810940Z","iopub.execute_input":"2022-12-17T08:34:47.812443Z","iopub.status.idle":"2022-12-17T08:34:47.823772Z","shell.execute_reply.started":"2022-12-17T08:34:47.812416Z","shell.execute_reply":"2022-12-17T08:34:47.822614Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"text = \"For coffee lovers.\"\ntext = text.lower()\nencoding = [word2int[word] for word in text.split()]\nreverse = \" \".join(word_array[enc] for enc in encoding)\nprint(encoding)\nprint(reverse)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:47.825612Z","iopub.execute_input":"2022-12-17T08:34:47.826204Z","iopub.status.idle":"2022-12-17T08:34:47.836920Z","shell.execute_reply.started":"2022-12-17T08:34:47.826163Z","shell.execute_reply":"2022-12-17T08:34:47.835553Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[362, 187, 594]\nfor coffee lovers.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nseq_length = 1\nchunk_size = seq_length + 1\ntext_chunks = [words_encoded[i:i+chunk_size] for i in range(len(words_encoded)-chunk_size)]\n","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:47.838416Z","iopub.execute_input":"2022-12-17T08:34:47.838947Z","iopub.status.idle":"2022-12-17T08:34:49.595370Z","shell.execute_reply.started":"2022-12-17T08:34:47.838764Z","shell.execute_reply":"2022-12-17T08:34:49.594543Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, text_chunks):\n        self.text_chunks = text_chunks\n\n    def __len__(self):\n        return len(self.text_chunks)\n\n    def __getitem__(self, idx):\n        text_chunk = self.text_chunks[idx]\n        return text_chunk[:-1].long(), text_chunk[1:].long()","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:49.596415Z","iopub.execute_input":"2022-12-17T08:34:49.597530Z","iopub.status.idle":"2022-12-17T08:34:49.603920Z","shell.execute_reply.started":"2022-12-17T08:34:49.597464Z","shell.execute_reply":"2022-12-17T08:34:49.602839Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"seq_dataset = TextDataset(torch.tensor(text_chunks))","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:49.607879Z","iopub.execute_input":"2022-12-17T08:34:49.608440Z","iopub.status.idle":"2022-12-17T08:34:49.617959Z","shell.execute_reply.started":"2022-12-17T08:34:49.608405Z","shell.execute_reply":"2022-12-17T08:34:49.617172Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, (seq, target) in enumerate(seq_dataset):\n    print(' Input (x): ',repr(''.join(word_array[seq])))\n    print('Target (y): ',repr(''.join(word_array[target])))\n    print()\n    if i == 1:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:49.618890Z","iopub.execute_input":"2022-12-17T08:34:49.619774Z","iopub.status.idle":"2022-12-17T08:34:49.630740Z","shell.execute_reply.started":"2022-12-17T08:34:49.619749Z","shell.execute_reply":"2022-12-17T08:34:49.629622Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":" Input (x):  'passion'\nTarget (y):  \"everyone's\"\n\n Input (x):  \"everyone's\"\nTarget (y):  'floaty'\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nbatch_size = 32\ntorch.manual_seed(1)\nseq_dl = DataLoader(seq_dataset, batch_size=batch_size,\nshuffle=True, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:49.632116Z","iopub.execute_input":"2022-12-17T08:34:49.632972Z","iopub.status.idle":"2022-12-17T08:34:49.642704Z","shell.execute_reply.started":"2022-12-17T08:34:49.632935Z","shell.execute_reply":"2022-12-17T08:34:49.641033Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nclass RNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.rnn_hidden_size = rnn_hidden_size\n        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size,\n        batch_first=True)\n        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n\n    def forward(self, x, hidden, cell):\n        out = self.embedding(x).unsqueeze(1)\n        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n        out = self.fc(out).reshape(out.size(0), -1)\n        return out, hidden, cell\n\n    def init_hidden(self, batch_size):\n        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n        return hidden, cell","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:49.643858Z","iopub.execute_input":"2022-12-17T08:34:49.644682Z","iopub.status.idle":"2022-12-17T08:34:49.654131Z","shell.execute_reply.started":"2022-12-17T08:34:49.644647Z","shell.execute_reply":"2022-12-17T08:34:49.652988Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"vocab_size = len(word_array)\nembed_dim = 256\nrnn_hidden_size = 512\ntorch.manual_seed(1)\nmodel = RNN(vocab_size, embed_dim, rnn_hidden_size)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:49.655383Z","iopub.execute_input":"2022-12-17T08:34:49.655851Z","iopub.status.idle":"2022-12-17T08:34:49.698822Z","shell.execute_reply.started":"2022-12-17T08:34:49.655826Z","shell.execute_reply":"2022-12-17T08:34:49.697998Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:49.699849Z","iopub.execute_input":"2022-12-17T08:34:49.700214Z","iopub.status.idle":"2022-12-17T08:34:49.705272Z","shell.execute_reply.started":"2022-12-17T08:34:49.700189Z","shell.execute_reply":"2022-12-17T08:34:49.704149Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"RNN(\n  (embedding): Embedding(1132, 256)\n  (rnn): LSTM(256, 512, batch_first=True)\n  (fc): Linear(in_features=512, out_features=1132, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:49.706515Z","iopub.execute_input":"2022-12-17T08:34:49.706894Z","iopub.status.idle":"2022-12-17T08:34:49.717064Z","shell.execute_reply.started":"2022-12-17T08:34:49.706870Z","shell.execute_reply":"2022-12-17T08:34:49.716063Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"num_epochs = 5000\ntorch.manual_seed(1)\nfor epoch in range(num_epochs):\n    hidden, cell = model.init_hidden(batch_size)\n    seq_batch, target_batch = next(iter(seq_dl))\n    optimizer.zero_grad()\n    loss = 0\n    for c in range(seq_length):\n        pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n        loss += loss_fn(pred, target_batch[:, c])\n    loss.backward()\n    optimizer.step()\n    loss = loss.item()/seq_length\n    if epoch % 500 == 0:\n        print(f'Epoch {epoch} loss: {loss:.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:34:49.718094Z","iopub.execute_input":"2022-12-17T08:34:49.718383Z","iopub.status.idle":"2022-12-17T08:36:46.787325Z","shell.execute_reply.started":"2022-12-17T08:34:49.718351Z","shell.execute_reply":"2022-12-17T08:36:46.786038Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 0 loss: 7.0425\nEpoch 500 loss: 0.0241\nEpoch 1000 loss: 0.0053\nEpoch 1500 loss: 0.0022\nEpoch 2000 loss: 0.0012\nEpoch 2500 loss: 0.0008\nEpoch 3000 loss: 0.0005\nEpoch 3500 loss: 0.0003\nEpoch 4000 loss: 0.0003\nEpoch 4500 loss: 0.0002\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.distributions.categorical import Categorical\ntorch.manual_seed(1)\nlogits = torch.tensor([[1.0, 1.0, 3.0]])\nprint('Probabilities:',nn.functional.softmax(logits, dim=1).numpy()[0])\n\nm = Categorical(logits=logits)\nsamples = m.sample((10,))\nprint(samples.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:36:46.788648Z","iopub.execute_input":"2022-12-17T08:36:46.789536Z","iopub.status.idle":"2022-12-17T08:36:46.803802Z","shell.execute_reply.started":"2022-12-17T08:36:46.789498Z","shell.execute_reply":"2022-12-17T08:36:46.802860Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Probabilities: [0.10650698 0.10650698 0.78698605]\n[[0]\n [2]\n [2]\n [1]\n [2]\n [1]\n [2]\n [2]\n [2]\n [2]]\n","output_type":"stream"}]},{"cell_type":"code","source":"def sample(model, starting_str,len_generated_text=5, scale_factor=1.0):\n    encoded_input = torch.tensor([word2int[s] for s in starting_str.split()])\n    encoded_input = torch.reshape(encoded_input, (1, -1))\n    generated_str = starting_str\n\n    model.eval()\n    hidden, cell = model.init_hidden(1)\n  \n    for c in range(len(starting_str.split())-1):\n        _, hidden, cell = model(encoded_input[:, c].view(1), hidden, cell)\n\n    last_char = encoded_input[:, -1]\n    for i in range(len_generated_text):\n         logits, hidden, cell = model(last_char.view(1), hidden, cell)\n         logits = torch.squeeze(logits, 0)\n         scaled_logits = logits * scale_factor\n         m = Categorical(logits=scaled_logits)\n         last_char = m.sample()\n    generated_str += str(word_array[last_char])\n\n    return generated_str\n","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:39:51.201305Z","iopub.execute_input":"2022-12-17T08:39:51.201651Z","iopub.status.idle":"2022-12-17T08:39:51.211100Z","shell.execute_reply.started":"2022-12-17T08:39:51.201625Z","shell.execute_reply":"2022-12-17T08:39:51.209784Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(1)\nprint(sample(model, starting_str='best'))","metadata":{"execution":{"iopub.status.busy":"2022-12-17T08:41:13.914650Z","iopub.execute_input":"2022-12-17T08:41:13.914974Z","iopub.status.idle":"2022-12-17T08:41:13.928276Z","shell.execute_reply.started":"2022-12-17T08:41:13.914947Z","shell.execute_reply":"2022-12-17T08:41:13.926977Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"bestmake.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}